# -*- coding: utf-8 -*-
"""TP1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RqMo5Mh7RZaju3KvewXqL-_4MaGuxMvm
"""

# -*- coding: utf-8 -*-
"""
Created on Thu Mar 27 13:55:33 2025

@author: cathe
"""

import numpy as np
from matplotlib import pyplot as plt


def plotGallery(images, n=16, title=None):
    # Affiche les n premières images contenues dans images
    # images est de taille Nb image*Ny*Nx
    n = min(n, images.shape[0])
    nSubplots = int(np.ceil(np.sqrt(n)))
    fig, axs = plt.subplots(nSubplots, nSubplots)
    for i in range(n):
        axs[i // nSubplots, i % nSubplots].imshow(images[i], cmap=plt.cm.gray)
        axs[i // nSubplots, i % nSubplots].set_xticks([])
        axs[i // nSubplots, i % nSubplots].set_yticks([])
    if title:
        plt.suptitle(title)
    plt.show()

def plotHistoClasses(lbls):
    # Affiche le nombre d'exemples par classe
    nLbls = np.array([[i, np.where(lbls == i)[0].shape[0]] for i in np.unique(lbls)])
    plt.figure()
    plt.bar(nLbls[:, 0], nLbls[:, 1])
    plt.title("Nombre d'exemples par classe")
    plt.grid(axis='y')
    plt.show()


# #############################################################################
# I Chargement des données

# I.a. Chargement de la base
[X, y, name]=np.load("TP1.npy",allow_pickle=True)
# Afficher les 12 premières images de la base
plotGallery(X, n=12, title="12 premières images")
# Afficher l'histogramme du nombre d'exemples par classe
plotHistoClasses(y)
# Infos sur les données
# -----------------------------------------------------
N, h, w = X.shape      # N = nb images, h=hauteur, w=largeur
n_classes = len(np.unique(y))

print("Taille d'une image :", h, "x", w, "pixels")
print("Nombre total d'images :", N)
print("Nombre de classes :", n_classes)
# Noms des 12 premières images
first12 = [name[int(lbl)] for lbl in y[:12]]
print("Identité des 12 premières images :", first12)
# Nombre d'images par classe
unique, counts = np.unique(y, return_counts=True)
for u, c in zip(unique, counts):
    print(f"Classe {u} ({name[int(u)]}) : {c} images")
# Vérifier si les classes sont équiprobables
if np.all(counts == counts[0]):
    print("Les classes sont équiprobables")
else:
    print("Les classes ne sont PAS équiprobables")

from sklearn.model_selection import train_test_split

# Partitionnement 75% train / 25% test avec reproductibilité
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=758, stratify=y
)

# Affichage des formes
print("X_train shape:", X_train.shape)
print("X_test shape :", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape :", y_test.shape)

# Affichage du nombre d'images
print("Nb images train :", len(X_train))
print("Nb images test  :", len(X_test))

# Nombre d'exemples
N_train = X_train.shape[0]
N_test  = X_test.shape[0]

# Redimensionnement
X_train_flat = X_train.reshape(N_train, -1)  # -1 = calcule automatiquement 62*47 = 2914
X_test_flat  = X_test.reshape(N_test, -1)

print("X_train_flat shape:", X_train_flat.shape)
print("X_test_flat shape :", X_test_flat.shape)

# 1. Chargement et partition
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, accuracy_score

X, y, name = np.load("TP1.npy", allow_pickle=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=758, stratify=y)

# 2. Redimensionnement
X_train_flat = X_train.reshape(X_train.shape[0], -1)
X_test_flat  = X_test.reshape(X_test.shape[0], -1)

# 3. Mise en forme (scaling)
scaler = StandardScaler()
scaler.fit(X_train_flat)        # calcul de la moyenne/écart-type sur le train
X_train_scaled = scaler.transform(X_train_flat)
X_test_scaled  = scaler.transform(X_test_flat)

# 4. Classifieur 1PPV
knn1 = KNeighborsClassifier(n_neighbors=1, metric='euclidean')
knn1.fit(X_train_scaled, y_train)
y_pred = knn1.predict(X_test_scaled)

# 5. Matrice de confusion et taux
cm = confusion_matrix(y_test, y_pred)
print("Matrice de confusion :\n", cm)
print("Taux de reconnaissance :", accuracy_score(y_test, y_pred))

from PIL import Image
from skimage.color import rgb2gray
from skimage.transform import resize

K_best = 1  # or the best K you found earlier
knn_best = KNeighborsClassifier(n_neighbors=K_best, metric='euclidean')
knn_best.fit(X_train_scaled, y_train)

# Load Powell image
I = np.array(Image.open("Powell.jpg"))
I_gray = rgb2gray(I)
I_resized = resize(I_gray, (62, 47), anti_aliasing=True)
I_flat = I_resized.reshape(1, -1)
I_scaled = scaler.transform(I_flat)

# Predict
y_pred_web = knn_best.predict(I_scaled)
print("Powell.jpg →", name[int(y_pred_web[0])])
Remove old TP1.py file
